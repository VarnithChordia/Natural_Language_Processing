{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Lecture 2, comprehension exercises for ML + NL.\n",
    "\n",
    "Matthew Stone   \n",
    "Initial version, Spring 2018   \n",
    "\n",
    "\n",
    "[Resampling for approximate permutation tests.][1]\n",
    "\n",
    "[1]:https://en.wikipedia.org/wiki/Resampling_(statistics)\n",
    "\n",
    "Rather than find an appropriate test statistic and interpret it according to a set procedure, it's often easier to simply simulate the results of your experiment assuming the null hypothesis (that is, assuming that any effects you observed were simply due to chance). You can use the fraction of time the simulation gets results similar to yours as an estimate of the  pp -value associated with your experimental results. This is technically known as an approximate permutation test in statistics.\n",
    "\n",
    "Here, we assume that there's no difference in overall accuracy between the results of two classifiers. That means it doesn't really matter which classifier made which prediction; if we swap the classifiers randomly, we'll get similar results. Here sim_expt proposes to swap items from p1 and p2 at random and see whether the resulting simulated experiment passes the passed test. The test we'll be interested in is whether the difference in accuracy between the \"two algorithms\" exceeds the difference we observed in the actual experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_expt(test, p1, p2):\n",
    "    '''apply test to a simulated experiment \n",
    "       where the difference between p1 and p2 is randomly erased'''\n",
    "    bits = [random.getrandbits(1) for i in range(0, len(p1))]\n",
    "    return test([p1[i] if bits[i] else p2[i] for i in range(0,len(p1))],\n",
    "                [p2[i] if bits[i] else p1[i] for i in range(0,len(p1))])\n",
    "\n",
    "def eval_diff(data, p1, p2) :\n",
    "    '''a test generator based on the performance difference between p1 and p2\n",
    "       asks whether the result of a simulated experiment is at least as extreme\n",
    "       as the observed accuracy difference between p1 and p2 on data'''\n",
    "    diff = abs(sklearn.metrics.accuracy_score(data, p1) -\n",
    "               sklearn.metrics.accuracy_score(data, p2))\n",
    "    def test_diff(n, m) :\n",
    "        return (abs(sklearn.metrics.accuracy_score(data, n) - \n",
    "                    sklearn.metrics.accuracy_score(data, m)) >= \n",
    "                diff)\n",
    "    return test_diff\n",
    "\n",
    "def mcmcp_diff(data, p1, p2, k) :\n",
    "    '''the approximate permuatation test\n",
    "       simulate an experiment like that used to obtain p1 and p2\n",
    "       forgetting any difference between p1 and p2\n",
    "       running the experiment k times\n",
    "       and record the probability that the performance difference on data\n",
    "       is as extreme as actually observed'''\n",
    "    success = 0\n",
    "    test = eval_diff(data, p1, p2)\n",
    "    for i in range(0,k) :\n",
    "        success += sim_expt(test, p1, p2)\n",
    "    return success / float(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2646"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.getrandbits(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise has two goals.\n",
    "- Understand this code and appreciate the reasoning behind it.\n",
    "- Get a feel for the kinds of results it gives: on the one hand, small data sets make it surprisingly difficult to detect even fairly substantial differences in performance; on the other hand, extremely large data sets can establish that even trivial differences are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "Define `data` to contain 100K uniformly random bits.\n",
    "\n",
    "Simulate an algorithm that classifies `data` with accuracy 80%, and store the results in `p1`\n",
    "\n",
    "Simulate an algorithm that classifies `data` with accuracy 83%, and store the results in `p2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.random.randint(2,size=100000)\n",
    "p1 = []\n",
    "p2 = []\n",
    "for i in range(len(data)):\n",
    "    if i in range(int(.8 *len(data))):\n",
    "        a = data[i]\n",
    "        p1.append(a)\n",
    "    else:\n",
    "        if data[i] == 0:\n",
    "            p1.append(1)\n",
    "        else:\n",
    "            p1.append(0)\n",
    "\n",
    "for j in range(len(data)):\n",
    "    if j in range(int(.83 *len(data))):\n",
    "        a = data[j]\n",
    "        p2.append(a)\n",
    "    else:\n",
    "        if data[j] == 0:\n",
    "            p2.append(1)\n",
    "        else:\n",
    "            p2.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array(p1)\n",
    "p2 = np.array(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a,b,c):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return list(a[p], b[p], c[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_values = unison_shuffled_copies(p1,p2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = shuffled_values[0]\n",
    "p2 = shuffled_values[1]\n",
    "data = shuffled_values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(p2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(p1,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability, I\n",
    "\n",
    "You can think of `data`, `p1`, and `p2` as\n",
    "- 1 big experiment of size 100K: E1\n",
    "- 10 experiments of size 10K: E10\n",
    "- 100 experiments of size 1K: E100\n",
    "- 1K experiments of size 100: E1000\n",
    "\n",
    "It's easy to see that the accuracy of `p1` and `p2` in E1 has to be equal to the average accuracy across all the other experiments.  What is it?\n",
    "\n",
    "It's more interesting to consider the standard deviations of the accuracy of `p1` and `p2` across experiments E10, E100, and E1000.  What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E10_P1 = p1.reshape(10,10000)\n",
    "E100_P1 = p1.reshape(100,1000)\n",
    "E1000_P1 = p1.reshape(1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E10_P2 = p2.reshape(10,10000)\n",
    "E100_P2 = p2.reshape(100,1000)\n",
    "E1000_P2 = p2.reshape(1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E10_data = data.reshape(10,10000)\n",
    "E100_data = data.reshape(100,1000)\n",
    "E1000_data = data.reshape(1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_name(data,exp):\n",
    "    acc_lst=[]\n",
    "    for i in range(len(data)):\n",
    "        count=0\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] == exp[i][j]:\n",
    "                count +=1\n",
    "        acc_lst.append(count/len(data[i]))\n",
    "    return np.array(acc_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8299999999999998"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = experiment_name(E10_data,E10_P2)\n",
    "np.mean(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For P1 across all the experiemnts is ~80% and across P2 it is ~83%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81, 0.86, 0.85, 0.83, 0.84, 0.84, 0.83, 0.76, 0.76, 0.8 , 0.8 ,\n",
       "       0.87, 0.77, 0.88, 0.81, 0.82, 0.83, 0.81, 0.82, 0.82, 0.85, 0.82,\n",
       "       0.83, 0.87, 0.76, 0.86, 0.79, 0.85, 0.81, 0.89, 0.87, 0.79, 0.86,\n",
       "       0.81, 0.85, 0.85, 0.87, 0.85, 0.85, 0.86, 0.77, 0.78, 0.81, 0.86,\n",
       "       0.8 , 0.84, 0.82, 0.86, 0.71, 0.86, 0.76, 0.82, 0.85, 0.81, 0.79,\n",
       "       0.84, 0.83, 0.81, 0.85, 0.81, 0.81, 0.8 , 0.85, 0.86, 0.94, 0.75,\n",
       "       0.79, 0.84, 0.84, 0.8 , 0.89, 0.83, 0.82, 0.83, 0.83, 0.83, 0.84,\n",
       "       0.83, 0.83, 0.91, 0.8 , 0.86, 0.83, 0.77, 0.79, 0.83, 0.83, 0.82,\n",
       "       0.81, 0.83, 0.86, 0.79, 0.83, 0.81, 0.82, 0.86, 0.91, 0.84, 0.78,\n",
       "       0.83, 0.81, 0.83, 0.78, 0.78, 0.81, 0.84, 0.87, 0.8 , 0.81, 0.85,\n",
       "       0.79, 0.84, 0.91, 0.85, 0.87, 0.82, 0.82, 0.84, 0.78, 0.82, 0.82,\n",
       "       0.83, 0.91, 0.91, 0.79, 0.89, 0.84, 0.79, 0.8 , 0.81, 0.74, 0.81,\n",
       "       0.75, 0.9 , 0.76, 0.86, 0.88, 0.83, 0.81, 0.81, 0.81, 0.84, 0.78,\n",
       "       0.8 , 0.8 , 0.87, 0.79, 0.85, 0.84, 0.83, 0.87, 0.86, 0.85, 0.93,\n",
       "       0.85, 0.82, 0.87, 0.77, 0.86, 0.84, 0.79, 0.77, 0.78, 0.86, 0.9 ,\n",
       "       0.82, 0.81, 0.84, 0.79, 0.79, 0.86, 0.83, 0.79, 0.82, 0.81, 0.85,\n",
       "       0.83, 0.78, 0.79, 0.82, 0.85, 0.86, 0.8 , 0.83, 0.82, 0.78, 0.71,\n",
       "       0.8 , 0.86, 0.84, 0.86, 0.8 , 0.78, 0.88, 0.88, 0.76, 0.88, 0.8 ,\n",
       "       0.77, 0.82, 0.83, 0.83, 0.85, 0.89, 0.76, 0.78, 0.8 , 0.85, 0.78,\n",
       "       0.87, 0.9 , 0.82, 0.83, 0.84, 0.84, 0.82, 0.83, 0.77, 0.8 , 0.83,\n",
       "       0.85, 0.84, 0.82, 0.81, 0.79, 0.85, 0.91, 0.85, 0.8 , 0.81, 0.84,\n",
       "       0.86, 0.84, 0.76, 0.81, 0.85, 0.79, 0.87, 0.76, 0.86, 0.88, 0.85,\n",
       "       0.83, 0.86, 0.88, 0.84, 0.78, 0.86, 0.81, 0.85, 0.83, 0.8 , 0.83,\n",
       "       0.79, 0.82, 0.8 , 0.81, 0.76, 0.89, 0.9 , 0.85, 0.87, 0.84, 0.89,\n",
       "       0.88, 0.87, 0.84, 0.85, 0.84, 0.81, 0.81, 0.8 , 0.76, 0.83, 0.84,\n",
       "       0.83, 0.83, 0.86, 0.87, 0.89, 0.81, 0.88, 0.81, 0.81, 0.84, 0.86,\n",
       "       0.79, 0.85, 0.87, 0.86, 0.88, 0.83, 0.84, 0.82, 0.88, 0.83, 0.85,\n",
       "       0.79, 0.84, 0.89, 0.87, 0.88, 0.83, 0.87, 0.82, 0.86, 0.81, 0.81,\n",
       "       0.78, 0.85, 0.85, 0.84, 0.78, 0.78, 0.79, 0.9 , 0.81, 0.83, 0.81,\n",
       "       0.81, 0.84, 0.85, 0.76, 0.8 , 0.8 , 0.8 , 0.88, 0.87, 0.79, 0.87,\n",
       "       0.88, 0.78, 0.9 , 0.75, 0.84, 0.82, 0.87, 0.91, 0.81, 0.87, 0.86,\n",
       "       0.85, 0.78, 0.88, 0.83, 0.82, 0.84, 0.85, 0.82, 0.85, 0.82, 0.83,\n",
       "       0.83, 0.9 , 0.79, 0.8 , 0.84, 0.9 , 0.87, 0.84, 0.83, 0.84, 0.86,\n",
       "       0.79, 0.92, 0.85, 0.82, 0.84, 0.85, 0.85, 0.8 , 0.8 , 0.84, 0.89,\n",
       "       0.85, 0.88, 0.88, 0.83, 0.86, 0.76, 0.82, 0.86, 0.85, 0.89, 0.83,\n",
       "       0.83, 0.78, 0.82, 0.81, 0.84, 0.82, 0.81, 0.84, 0.92, 0.88, 0.83,\n",
       "       0.78, 0.81, 0.86, 0.89, 0.81, 0.78, 0.76, 0.83, 0.88, 0.85, 0.75,\n",
       "       0.8 , 0.83, 0.72, 0.85, 0.83, 0.85, 0.88, 0.82, 0.8 , 0.84, 0.85,\n",
       "       0.86, 0.81, 0.88, 0.82, 0.83, 0.82, 0.78, 0.88, 0.78, 0.75, 0.83,\n",
       "       0.8 , 0.75, 0.73, 0.78, 0.78, 0.78, 0.83, 0.85, 0.83, 0.77, 0.84,\n",
       "       0.88, 0.83, 0.85, 0.83, 0.78, 0.8 , 0.91, 0.84, 0.83, 0.77, 0.82,\n",
       "       0.86, 0.75, 0.84, 0.82, 0.83, 0.79, 0.81, 0.9 , 0.83, 0.86, 0.8 ,\n",
       "       0.87, 0.79, 0.78, 0.85, 0.86, 0.89, 0.8 , 0.82, 0.9 , 0.9 , 0.81,\n",
       "       0.9 , 0.84, 0.8 , 0.85, 0.81, 0.83, 0.89, 0.85, 0.79, 0.84, 0.83,\n",
       "       0.82, 0.83, 0.81, 0.86, 0.8 , 0.78, 0.9 , 0.83, 0.79, 0.91, 0.9 ,\n",
       "       0.9 , 0.88, 0.85, 0.73, 0.87, 0.81, 0.84, 0.85, 0.83, 0.87, 0.81,\n",
       "       0.84, 0.85, 0.79, 0.87, 0.8 , 0.82, 0.82, 0.82, 0.8 , 0.84, 0.85,\n",
       "       0.78, 0.73, 0.83, 0.85, 0.77, 0.82, 0.85, 0.75, 0.85, 0.84, 0.78,\n",
       "       0.83, 0.79, 0.93, 0.85, 0.76, 0.81, 0.8 , 0.8 , 0.79, 0.87, 0.86,\n",
       "       0.83, 0.76, 0.84, 0.86, 0.81, 0.84, 0.79, 0.8 , 0.83, 0.83, 0.85,\n",
       "       0.8 , 0.77, 0.78, 0.79, 0.77, 0.83, 0.8 , 0.78, 0.83, 0.85, 0.79,\n",
       "       0.83, 0.76, 0.8 , 0.78, 0.89, 0.87, 0.8 , 0.8 , 0.84, 0.88, 0.88,\n",
       "       0.89, 0.85, 0.89, 0.83, 0.79, 0.8 , 0.84, 0.8 , 0.84, 0.88, 0.81,\n",
       "       0.84, 0.83, 0.84, 0.84, 0.87, 0.85, 0.82, 0.82, 0.78, 0.79, 0.85,\n",
       "       0.78, 0.83, 0.8 , 0.82, 0.75, 0.81, 0.81, 0.82, 0.76, 0.87, 0.84,\n",
       "       0.82, 0.86, 0.82, 0.79, 0.83, 0.77, 0.88, 0.78, 0.87, 0.9 , 0.87,\n",
       "       0.86, 0.87, 0.81, 0.81, 0.8 , 0.76, 0.83, 0.85, 0.78, 0.88, 0.84,\n",
       "       0.85, 0.81, 0.82, 0.86, 0.84, 0.87, 0.82, 0.86, 0.76, 0.87, 0.8 ,\n",
       "       0.89, 0.8 , 0.88, 0.89, 0.83, 0.82, 0.85, 0.85, 0.84, 0.82, 0.88,\n",
       "       0.81, 0.76, 0.85, 0.85, 0.83, 0.79, 0.79, 0.88, 0.83, 0.83, 0.83,\n",
       "       0.8 , 0.86, 0.86, 0.86, 0.8 , 0.84, 0.84, 0.81, 0.83, 0.85, 0.85,\n",
       "       0.88, 0.86, 0.82, 0.82, 0.86, 0.84, 0.81, 0.84, 0.84, 0.83, 0.81,\n",
       "       0.83, 0.84, 0.78, 0.81, 0.82, 0.85, 0.79, 0.88, 0.77, 0.86, 0.77,\n",
       "       0.83, 0.86, 0.83, 0.81, 0.82, 0.83, 0.82, 0.88, 0.88, 0.88, 0.83,\n",
       "       0.86, 0.81, 0.8 , 0.77, 0.84, 0.87, 0.83, 0.84, 0.8 , 0.88, 0.84,\n",
       "       0.86, 0.76, 0.79, 0.88, 0.79, 0.81, 0.87, 0.78, 0.85, 0.83, 0.83,\n",
       "       0.83, 0.87, 0.73, 0.81, 0.84, 0.8 , 0.84, 0.84, 0.82, 0.89, 0.86,\n",
       "       0.89, 0.84, 0.85, 0.79, 0.84, 0.86, 0.86, 0.85, 0.79, 0.79, 0.91,\n",
       "       0.78, 0.83, 0.79, 0.85, 0.88, 0.8 , 0.81, 0.78, 0.82, 0.83, 0.81,\n",
       "       0.8 , 0.9 , 0.86, 0.82, 0.82, 0.87, 0.86, 0.79, 0.84, 0.79, 0.84,\n",
       "       0.81, 0.87, 0.85, 0.81, 0.86, 0.8 , 0.87, 0.82, 0.84, 0.83, 0.88,\n",
       "       0.9 , 0.83, 0.83, 0.8 , 0.8 , 0.87, 0.88, 0.78, 0.81, 0.88, 0.87,\n",
       "       0.81, 0.82, 0.77, 0.83, 0.78, 0.8 , 0.85, 0.77, 0.81, 0.85, 0.81,\n",
       "       0.79, 0.9 , 0.79, 0.8 , 0.82, 0.87, 0.84, 0.82, 0.91, 0.79, 0.83,\n",
       "       0.82, 0.79, 0.85, 0.91, 0.82, 0.93, 0.9 , 0.9 , 0.8 , 0.82, 0.83,\n",
       "       0.81, 0.87, 0.85, 0.83, 0.79, 0.88, 0.85, 0.86, 0.86, 0.85, 0.83,\n",
       "       0.83, 0.87, 0.83, 0.91, 0.85, 0.81, 0.85, 0.84, 0.84, 0.83, 0.8 ,\n",
       "       0.8 , 0.86, 0.91, 0.8 , 0.75, 0.83, 0.76, 0.85, 0.84, 0.88, 0.86,\n",
       "       0.83, 0.82, 0.81, 0.88, 0.79, 0.8 , 0.77, 0.83, 0.83, 0.84, 0.84,\n",
       "       0.83, 0.82, 0.87, 0.85, 0.86, 0.82, 0.77, 0.81, 0.8 , 0.78, 0.85,\n",
       "       0.87, 0.87, 0.9 , 0.86, 0.89, 0.77, 0.9 , 0.76, 0.82, 0.85, 0.78,\n",
       "       0.83, 0.91, 0.84, 0.87, 0.84, 0.86, 0.84, 0.81, 0.77, 0.83, 0.86,\n",
       "       0.73, 0.81, 0.78, 0.89, 0.82, 0.83, 0.82, 0.86, 0.84, 0.86, 0.83,\n",
       "       0.74, 0.86, 0.89, 0.93, 0.86, 0.76, 0.81, 0.81, 0.83, 0.78, 0.81,\n",
       "       0.82, 0.81, 0.81, 0.77, 0.81, 0.86, 0.82, 0.86, 0.83, 0.85, 0.71,\n",
       "       0.83, 0.84, 0.79, 0.88, 0.84, 0.91, 0.8 , 0.87, 0.78, 0.9 , 0.85,\n",
       "       0.79, 0.85, 0.82, 0.84, 0.88, 0.81, 0.82, 0.83, 0.8 , 0.82, 0.84,\n",
       "       0.74, 0.82, 0.88, 0.82, 0.79, 0.83, 0.87, 0.84, 0.77, 0.8 , 0.81,\n",
       "       0.87, 0.79, 0.82, 0.87, 0.86, 0.88, 0.83, 0.75, 0.87, 0.82, 0.85,\n",
       "       0.82, 0.9 , 0.88, 0.87, 0.79, 0.87, 0.85, 0.81, 0.82, 0.82, 0.84,\n",
       "       0.79, 0.8 , 0.86, 0.8 , 0.82, 0.84, 0.81, 0.85, 0.85, 0.85])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = experiment_name(E1000_data,E1000_P1,E1000_P2)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 0.004750578912090627\n",
      "E100 0.012979984591670357\n",
      "E1000 0.03804471053904865\n"
     ]
    }
   ],
   "source": [
    "print('E10',np.std(experiment_name(E10_data,E10_P2)))\n",
    "print('E100',np.std(experiment_name(E100_data,E100_P2)))\n",
    "print('E1000',np.std(experiment_name(E1000_data,E1000_P2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion across the mean is higher when smaller number of observations are used for experiments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability, II\n",
    "\n",
    "Another way of asking a similar question: in how many of the experiments in E10, E100 and E1000, does p1 (misleadingly) wind up with better performance than p2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_variability(data,exp1,exp2):\n",
    "    W = experiment_name(data,exp1)\n",
    "    W1 = experiment_name(data,exp2)\n",
    "    count=0\n",
    "    assert len(W)==len(W1)\n",
    "    for i in range(len(W)):\n",
    "        if W1[i] > W[i]:\n",
    "            count+=1\n",
    "    return count,len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(967, 1000)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_variability(E1000_data,E1000_P1,E1000_P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_variability(E100_data,E100_P1,E100_P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_variability(E10_data,E10_P1,E10_P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance\n",
    "\n",
    "Take a random experiment in each of E10, E100, and E1000.  What is the chance probability of a difference as large as what you see, according to the approximate permutation test, with k=2500?  (You are trading off accuracy versus waiting with this number.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2464"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmcp_diff(E1000_data[0], E1000_P1[0], E1000_P2[0], 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Larger experiments with smaller observations have higher value than a p-value of .05, so we fail to reject the null hypothesis and the accuracy we noticed were due to chance. But smaller experiments with larger observations does not bear such a high probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
